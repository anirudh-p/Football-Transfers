{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREAMBLE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from scipy.cluster import hierarchy as hc\n",
    "import scipy\n",
    "\n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "\n",
    "# import graph objects as \"go\"\n",
    "import plotly.graph_objs as go\n",
    "import plotly \n",
    "\n",
    "# For Partial Dependence Plots\n",
    "from pdpbox import pdp\n",
    "from plotnine import *\n",
    "\n",
    "# Import matplotlib for plotting and use magic command for Jupyter Notebooks\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "# *LOADING THE DATA*\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Data from CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_Dataframe = pd.read_csv(\"Data/FUT_ML_cleaned_data.csv\")  \n",
    "Main_Dataframe = Main_Dataframe.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>intl_rep</th>\n",
       "      <th>pace</th>\n",
       "      <th>pace_acceleration</th>\n",
       "      <th>pace_sprint_speed</th>\n",
       "      <th>dribbling</th>\n",
       "      <th>drib_agility</th>\n",
       "      <th>...</th>\n",
       "      <th>def_workrate_Med</th>\n",
       "      <th>Year_2016</th>\n",
       "      <th>Year_2017</th>\n",
       "      <th>Year_2018</th>\n",
       "      <th>Year_2019</th>\n",
       "      <th>Year_2020</th>\n",
       "      <th>ln_ps4_min</th>\n",
       "      <th>ln_ps4_max</th>\n",
       "      <th>ln_ps4_last</th>\n",
       "      <th>ln_avg_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>32</td>\n",
       "      <td>170</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.849398</td>\n",
       "      <td>14.808762</td>\n",
       "      <td>12.598115</td>\n",
       "      <td>13.329080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>34</td>\n",
       "      <td>185</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.043554</td>\n",
       "      <td>14.978661</td>\n",
       "      <td>12.923912</td>\n",
       "      <td>13.511108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>35</td>\n",
       "      <td>180</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.043249</td>\n",
       "      <td>13.017003</td>\n",
       "      <td>10.968198</td>\n",
       "      <td>11.530126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>33</td>\n",
       "      <td>193</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.388995</td>\n",
       "      <td>13.304685</td>\n",
       "      <td>10.484306</td>\n",
       "      <td>11.846840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>32</td>\n",
       "      <td>182</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.289782</td>\n",
       "      <td>14.220976</td>\n",
       "      <td>11.542484</td>\n",
       "      <td>12.755379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96438</td>\n",
       "      <td>87</td>\n",
       "      <td>20</td>\n",
       "      <td>178</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.126631</td>\n",
       "      <td>13.081541</td>\n",
       "      <td>12.185870</td>\n",
       "      <td>11.604086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96439</td>\n",
       "      <td>86</td>\n",
       "      <td>22</td>\n",
       "      <td>178</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.126631</td>\n",
       "      <td>13.081541</td>\n",
       "      <td>11.177453</td>\n",
       "      <td>11.604086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96440</td>\n",
       "      <td>85</td>\n",
       "      <td>20</td>\n",
       "      <td>178</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.615805</td>\n",
       "      <td>12.577636</td>\n",
       "      <td>11.561716</td>\n",
       "      <td>11.096721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96441</td>\n",
       "      <td>85</td>\n",
       "      <td>20</td>\n",
       "      <td>170</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.615805</td>\n",
       "      <td>12.577636</td>\n",
       "      <td>11.385092</td>\n",
       "      <td>11.096721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96442</td>\n",
       "      <td>85</td>\n",
       "      <td>21</td>\n",
       "      <td>181</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.903488</td>\n",
       "      <td>12.847927</td>\n",
       "      <td>12.095141</td>\n",
       "      <td>11.375707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96443 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall  age  height  weight  intl_rep  pace  pace_acceleration  \\\n",
       "0           94   32     170    72.0       0.0  92.0               95.0   \n",
       "1           93   34     185    80.0       0.0  92.0               91.0   \n",
       "2           90   35     180    80.0       0.0  92.0               92.0   \n",
       "3           90   33     193    92.0       0.0   0.0               58.0   \n",
       "4           90   32     182    85.0       0.0  82.0               88.0   \n",
       "...        ...  ...     ...     ...       ...   ...                ...   \n",
       "96438       87   20     178    68.0       0.0  81.0               79.0   \n",
       "96439       86   22     178    70.0       0.0  84.0               86.0   \n",
       "96440       85   20     178    73.0       0.0  90.0               92.0   \n",
       "96441       85   20     170    65.0       0.0  92.0               92.0   \n",
       "96442       85   21     181    79.0       0.0  89.0               87.0   \n",
       "\n",
       "       pace_sprint_speed  dribbling  drib_agility  ...  def_workrate_Med  \\\n",
       "0                   90.0       95.0          92.0  ...                 0   \n",
       "1                   93.0       90.0          90.0  ...                 0   \n",
       "2                   92.0       92.0          91.0  ...                 0   \n",
       "3                   61.0        0.0          43.0  ...                 1   \n",
       "4                   78.0       88.0          86.0  ...                 1   \n",
       "...                  ...        ...           ...  ...               ...   \n",
       "96438               81.0       83.0          85.0  ...                 1   \n",
       "96439               82.0       86.0          88.0  ...                 0   \n",
       "96440               87.0       88.0          98.0  ...                 1   \n",
       "96441               92.0       88.0          97.0  ...                 1   \n",
       "96442               89.0       83.0          87.0  ...                 1   \n",
       "\n",
       "       Year_2016  Year_2017  Year_2018  Year_2019  Year_2020  ln_ps4_min  \\\n",
       "0              1          0          0          0          0   11.849398   \n",
       "1              1          0          0          0          0   12.043554   \n",
       "2              1          0          0          0          0   10.043249   \n",
       "3              1          0          0          0          0   10.388995   \n",
       "4              1          0          0          0          0   11.289782   \n",
       "...          ...        ...        ...        ...        ...         ...   \n",
       "96438          0          0          0          0          1   10.126631   \n",
       "96439          0          0          0          0          1   10.126631   \n",
       "96440          0          0          0          0          1    9.615805   \n",
       "96441          0          0          0          0          1    9.615805   \n",
       "96442          0          0          0          0          1    9.903488   \n",
       "\n",
       "       ln_ps4_max  ln_ps4_last  ln_avg_price  \n",
       "0       14.808762    12.598115     13.329080  \n",
       "1       14.978661    12.923912     13.511108  \n",
       "2       13.017003    10.968198     11.530126  \n",
       "3       13.304685    10.484306     11.846840  \n",
       "4       14.220976    11.542484     12.755379  \n",
       "...           ...          ...           ...  \n",
       "96438   13.081541    12.185870     11.604086  \n",
       "96439   13.081541    11.177453     11.604086  \n",
       "96440   12.577636    11.561716     11.096721  \n",
       "96441   12.577636    11.385092     11.096721  \n",
       "96442   12.847927    12.095141     11.375707  \n",
       "\n",
       "[96443 rows x 89 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main_Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We now try to further clean the dataset by replacing the current ages of the icons (which do not add value since their peak attributes are used) with an imputed value of their age.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_Dataframe.loc[Main_Dataframe['age'] > 40, 'age_imputed'] = np.nan\n",
    "Main_Dataframe.loc[Main_Dataframe['age'] <= 40, 'age_imputed'] = Main_Dataframe['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the NaN ages randomly using a distribution of the remaining ages\n",
    "Main_Dataframe['age_imputed'] = Main_Dataframe.age_imputed.fillna(int(np.random.normal(28.97,4.08,1)))\n",
    "\n",
    "# N.B: Mean and Standard deviation taken from the Main_Dataframe['age_imputed'].describe(). Assumed a normal distribution of the \n",
    "#      ages in our sample and imupted age is randomly selected from this distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>intl_rep</th>\n",
       "      <th>pace</th>\n",
       "      <th>pace_acceleration</th>\n",
       "      <th>pace_sprint_speed</th>\n",
       "      <th>dribbling</th>\n",
       "      <th>drib_agility</th>\n",
       "      <th>drib_balance</th>\n",
       "      <th>...</th>\n",
       "      <th>Year_2016</th>\n",
       "      <th>Year_2017</th>\n",
       "      <th>Year_2018</th>\n",
       "      <th>Year_2019</th>\n",
       "      <th>Year_2020</th>\n",
       "      <th>ln_ps4_min</th>\n",
       "      <th>ln_ps4_max</th>\n",
       "      <th>ln_ps4_last</th>\n",
       "      <th>ln_avg_price</th>\n",
       "      <th>age_imputed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>96443.000000</td>\n",
       "      <td>96443.000000</td>\n",
       "      <td>96443.000000</td>\n",
       "      <td>96443.000000</td>\n",
       "      <td>96443.000000</td>\n",
       "      <td>96443.000000</td>\n",
       "      <td>96443.000000</td>\n",
       "      <td>96443.000000</td>\n",
       "      <td>96443.000000</td>\n",
       "      <td>96443.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>96443.000000</td>\n",
       "      <td>96443.000000</td>\n",
       "      <td>96443.000000</td>\n",
       "      <td>96443.000000</td>\n",
       "      <td>96443.000000</td>\n",
       "      <td>96443.000000</td>\n",
       "      <td>96443.000000</td>\n",
       "      <td>96443.000000</td>\n",
       "      <td>96443.000000</td>\n",
       "      <td>96443.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>68.503251</td>\n",
       "      <td>181.394202</td>\n",
       "      <td>74.777983</td>\n",
       "      <td>0.949493</td>\n",
       "      <td>62.261429</td>\n",
       "      <td>66.416961</td>\n",
       "      <td>66.635889</td>\n",
       "      <td>57.825337</td>\n",
       "      <td>65.366600</td>\n",
       "      <td>64.801593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204805</td>\n",
       "      <td>0.208724</td>\n",
       "      <td>0.209823</td>\n",
       "      <td>0.189687</td>\n",
       "      <td>0.186960</td>\n",
       "      <td>5.645623</td>\n",
       "      <td>9.410865</td>\n",
       "      <td>6.664882</td>\n",
       "      <td>7.528244</td>\n",
       "      <td>27.792831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>8.358415</td>\n",
       "      <td>6.734672</td>\n",
       "      <td>10.453511</td>\n",
       "      <td>0.735174</td>\n",
       "      <td>24.157336</td>\n",
       "      <td>15.175536</td>\n",
       "      <td>14.890294</td>\n",
       "      <td>22.655147</td>\n",
       "      <td>15.390584</td>\n",
       "      <td>14.635981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403561</td>\n",
       "      <td>0.406399</td>\n",
       "      <td>0.407185</td>\n",
       "      <td>0.392056</td>\n",
       "      <td>0.389882</td>\n",
       "      <td>1.270685</td>\n",
       "      <td>0.712020</td>\n",
       "      <td>1.657810</td>\n",
       "      <td>0.968167</td>\n",
       "      <td>4.534930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.605170</td>\n",
       "      <td>8.517193</td>\n",
       "      <td>5.298317</td>\n",
       "      <td>6.763914</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.010635</td>\n",
       "      <td>9.210340</td>\n",
       "      <td>5.298317</td>\n",
       "      <td>7.110488</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.010635</td>\n",
       "      <td>9.210340</td>\n",
       "      <td>6.214608</td>\n",
       "      <td>7.110488</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.703782</td>\n",
       "      <td>9.210340</td>\n",
       "      <td>7.244228</td>\n",
       "      <td>7.457061</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.100690</td>\n",
       "      <td>16.523561</td>\n",
       "      <td>16.432906</td>\n",
       "      <td>15.312125</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            overall        height        weight      intl_rep          pace  \\\n",
       "count  96443.000000  96443.000000  96443.000000  96443.000000  96443.000000   \n",
       "mean      68.503251    181.394202     74.777983      0.949493     62.261429   \n",
       "std        8.358415      6.734672     10.453511      0.735174     24.157336   \n",
       "min       44.000000    155.000000      0.000000      0.000000      0.000000   \n",
       "25%       63.000000    177.000000     70.000000      1.000000     59.000000   \n",
       "50%       68.000000    182.000000     75.000000      1.000000     69.000000   \n",
       "75%       73.000000    186.000000     80.000000      1.000000     77.000000   \n",
       "max       99.000000    208.000000    110.000000      5.000000     99.000000   \n",
       "\n",
       "       pace_acceleration  pace_sprint_speed     dribbling  drib_agility  \\\n",
       "count       96443.000000       96443.000000  96443.000000  96443.000000   \n",
       "mean           66.416961          66.635889     57.825337     65.366600   \n",
       "std            15.175536          14.890294     22.655147     15.390584   \n",
       "min             0.000000           0.000000      0.000000      0.000000   \n",
       "25%            58.000000          59.000000     54.000000     57.000000   \n",
       "50%            69.000000          69.000000     64.000000     68.000000   \n",
       "75%            77.000000          77.000000     71.000000     76.000000   \n",
       "max            99.000000          99.000000     99.000000     99.000000   \n",
       "\n",
       "       drib_balance  ...     Year_2016     Year_2017     Year_2018  \\\n",
       "count  96443.000000  ...  96443.000000  96443.000000  96443.000000   \n",
       "mean      64.801593  ...      0.204805      0.208724      0.209823   \n",
       "std       14.635981  ...      0.403561      0.406399      0.407185   \n",
       "min        0.000000  ...      0.000000      0.000000      0.000000   \n",
       "25%       56.000000  ...      0.000000      0.000000      0.000000   \n",
       "50%       66.000000  ...      0.000000      0.000000      0.000000   \n",
       "75%       75.000000  ...      0.000000      0.000000      0.000000   \n",
       "max       99.000000  ...      1.000000      1.000000      1.000000   \n",
       "\n",
       "          Year_2019     Year_2020    ln_ps4_min    ln_ps4_max   ln_ps4_last  \\\n",
       "count  96443.000000  96443.000000  96443.000000  96443.000000  96443.000000   \n",
       "mean       0.189687      0.186960      5.645623      9.410865      6.664882   \n",
       "std        0.392056      0.389882      1.270685      0.712020      1.657810   \n",
       "min        0.000000      0.000000      4.605170      8.517193      5.298317   \n",
       "25%        0.000000      0.000000      5.010635      9.210340      5.298317   \n",
       "50%        0.000000      0.000000      5.010635      9.210340      6.214608   \n",
       "75%        0.000000      0.000000      5.703782      9.210340      7.244228   \n",
       "max        1.000000      1.000000     14.100690     16.523561     16.432906   \n",
       "\n",
       "       ln_avg_price   age_imputed  \n",
       "count  96443.000000  96443.000000  \n",
       "mean       7.528244     27.792831  \n",
       "std        0.968167      4.534930  \n",
       "min        6.763914     17.000000  \n",
       "25%        7.110488     24.000000  \n",
       "50%        7.110488     28.000000  \n",
       "75%        7.457061     31.000000  \n",
       "max       15.312125     40.000000  \n",
       "\n",
       "[8 rows x 89 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main_Dataframe['age'] = Main_Dataframe['age_imputed']\n",
    "Main_Dataframe = Main_Dataframe.drop('age',axis=1)\n",
    "Main_Dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a smaller random sample of the Main Dataframe\n",
    "x=Main_Dataframe.sample(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "# *Functions*\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Simple Function to calculate the error metric (Root Mean Standard Error)** *Taken from the fast.ai Notebook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Baseline error metric is Root Mean Square Error\n",
    "def rmse(x,y): return math.sqrt(((x-y)**2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Function for the Random Forest Process** *Doc strings will be added later for documentation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our Customized Random Forest Function\n",
    "def randomforest_customized(input_dataframe,y,list_drop,split_ratio=0.25,fi=False,fi_hist=False,fi_threshold=0.01,datasets_return=False,oob = False):\n",
    "    \n",
    "# STEP 1: GET THE LIST OF FEATURES AND THE TARGET LABEL:\n",
    "    # Labels are the values we want to predict\n",
    "    labels = input_dataframe[y]\n",
    "    \n",
    "    list_drop.append(y)\n",
    "    \n",
    "    # Remove the labels from the features\n",
    "    features = input_dataframe.drop(list_drop,axis=1)\n",
    "\n",
    "    # Saving feature names for later use\n",
    "    feature_list = features.columns.tolist()\n",
    "\n",
    "# STEP 2: SPLIT THE DATASET:\n",
    "    # Split the data into training and testing sets: The answer to life, universe and everything\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = split_ratio, random_state = 42) \n",
    "    \n",
    "    #For validation of the shape size\n",
    "    print('Training Features Shape :', train_features.shape)\n",
    "    print('Training Labels Shape   :', train_labels.shape)\n",
    "    print('Testing Features Shape  :', test_features.shape)\n",
    "    print('Testing Labels Shape    :', test_labels.shape)\n",
    "    print('')\n",
    "    \n",
    "# STEP 3: RUN THE PREDICTIONS:\n",
    "    # Initiate Random Forest Regressor (with or without the OOB as requested)\n",
    "    if oob == True:\n",
    "        rf = RandomForestRegressor(oob_score = True)\n",
    "    else:\n",
    "        rf = RandomForestRegressor()\n",
    "        \n",
    "    # Train the model on training data by fitting\n",
    "    %time rf.fit(train_features, train_labels)\n",
    "\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions_basic_model = rf.predict(test_features)\n",
    "\n",
    "# STEP 4: CALCULATE THE METRICS SCORES:\n",
    "    #Print the Metrics by datatype\n",
    "    rmse_train      = rmse(rf.predict(train_features), train_labels)\n",
    "    rmse_validation = rmse(rf.predict(test_features), test_labels)\n",
    "    r2_train        = rf.score(train_features, train_labels) \n",
    "    r2_validation   = rf.score(test_features, test_labels)\n",
    "    \n",
    "    if oob == True:\n",
    "        oob_stat = rf.oob_score_\n",
    "    else:\n",
    "        oob_stat = 'Not Reported' \n",
    "    \n",
    "    print('')\n",
    "    print('RMSE Training Data   :',rmse_train)\n",
    "    print('RMSE Validation Data :',rmse_validation)\n",
    "    print('R^2 Training Data    :',r2_train)\n",
    "    print('R^2 Validation Data  :',r2_validation)\n",
    "    print('Out-of-Bag Score     :',oob_stat)\n",
    "    \n",
    "# STEP 5: REPORT FEATURE IMPORTANCE (IF CALLED) AND PRINT THOSE ABOVE THE THRESHOLD:\n",
    "    # Get numerical feature importances\n",
    "    importances = list(rf.feature_importances_)\n",
    "    \n",
    "    if fi == True:\n",
    "        print('')\n",
    "        print('FEATURE IMPORTANCES')\n",
    "        print\n",
    "        \n",
    "        # List of tuples with variable and importance\n",
    "        feature_importances = [(feature, round(importance, 4)) for feature, importance in zip(feature_list, importances)]\n",
    "                     \n",
    "        # Extract some of the  most important features\n",
    "        important_features = [feature_tuple for feature_tuple in feature_importances if (feature_tuple[1] >= fi_threshold)]\n",
    "        \n",
    "        # Store the feature importances in a single list\n",
    "        important_features_list_all = [feature_tuple[0] for feature_tuple in feature_importances if feature_tuple[1]] \n",
    "        \n",
    "        # List of Important Features (as a function of threshold)\n",
    "        important_features_list_major = [feature_tuple[0] for feature_tuple in feature_importances if feature_tuple[1] > 0.0090] \n",
    "        \n",
    "\n",
    "        # Print out the feature and importances \n",
    "        [print('Variable: {:20} Importance: {}'.format(*pair)) for pair in important_features]\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# STEP 5.1: PLOT FEATURE IMPORTANCE HISTOGRAM (IF CALLED):\n",
    "    if fi_hist == True:\n",
    "\n",
    "        # Set the style\n",
    "        plt.style.use('fivethirtyeight')                 # Requires matplotlib.pyplot to be installed\n",
    "\n",
    "        # list of x locations for plotting\n",
    "        x_values = range(len(importances))\n",
    "\n",
    "        # Make a bar chart\n",
    "        plt.bar(x_values, importances, orientation = 'vertical')\n",
    "\n",
    "        # Tick labels for x axis\n",
    "        plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "\n",
    "        # Axis labels and title\n",
    "        plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');\n",
    "  \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# STEP 6: RETURNING RESULTS:    \n",
    "    model = rf\n",
    "    \n",
    "    # STEP 6.1: SOME POST ESTIMATION OUTPUTS THAT CAN BE USED FOR ANALYSIS:\n",
    "    imp_features = dict({'All_Feats':important_features_list_all,\n",
    "                         'Imp_Feats':important_features_list_major})\n",
    "\n",
    "    \n",
    "    # STEP 6.2: THE MODEL DATASETS AS SPLIT THAT CAN BE USED FOR ANALYSIS:\n",
    "    dataset_requested = dict({'Train_Feats':train_features, \n",
    "                              'Test_Feats':test_features, \n",
    "                              'Train_Labels':train_labels,\n",
    "                              'Test_Labels':test_labels})\n",
    "\n",
    "    rf_output_dict = {'Model':model}\n",
    "    \n",
    "    if fi == True:\n",
    "        rf_output_dict.update(imp_features)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if datasets_return == True:\n",
    "        rf_output_dict.update(dataset_requested)\n",
    "    else:\n",
    "        pass\n",
    " \n",
    "    return rf_output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running our first Random Forest Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape : (3750, 85)\n",
      "Training Labels Shape   : (3750,)\n",
      "Testing Features Shape  : (1250, 85)\n",
      "Testing Labels Shape    : (1250,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RUN ONLY ONCE, THEN COMMENT OUT SINCE AN INSTANCE TAKES ABOUT 5-7 MINS\n",
    "\n",
    "model_1 = randomforest_customized(input_dataframe=x, #Substitute x with Main_Dataframe when running final model\n",
    "                                 y='ln_ps4_last',\n",
    "                                 list_drop=['ln_ps4_min','ln_ps4_max','ln_avg_price'],\n",
    "                                 split_ratio=0.25,\n",
    "                                 fi=True,\n",
    "                                 fi_hist=True,\n",
    "                                 datasets_return=True,\n",
    "                                 oob=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "**Even a simple machine thus seems to substantially better both in terms of prediction as well as fit!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"> \n",
    "    \n",
    "**However we see a massive discrepency between the Training Dataset and Testing Dataset Predictions. What could explain this?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"> \n",
    "    \n",
    "# DATA DISTRIBUTION: Outliers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing the Outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_value = 10000\n",
    "cutoff = math.log(minimum_value,math.e)\n",
    "Main_Dataframe_Outliers = Main_Dataframe[Main_Dataframe['ln_ps4_last']>cutoff]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running the Random Forest for this subset of Outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Outliers = randomforest_customized(input_dataframe=Main_Dataframe_Outliers,\n",
    "                                                       y='ln_ps4_last',\n",
    "                                               list_drop=['ln_ps4_min','ln_ps4_max','ln_avg_price'],\n",
    "                                             split_ratio=0.25,\n",
    "                                                     fi = True,\n",
    "                                                 fi_hist=True,\n",
    "                                            fi_threshold=0.009,\n",
    "                                                     oob=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "#### The discrepency has vanished. The Machine Now does even better both in terms of prediction as well as fit! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "*Thus for immediate purposes, instead of building a general model, we restrict our attention to the valuable players auction. This is also more interesting, since we see the most fluctuation and these auction attract the most attention of FUT players*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"info\">\n",
    "\n",
    "# **SECOND MODEL**: USING ONLY THE \"IMPORTANT FEATURES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = ['ln_ps4_last']\n",
    "important_features = model_Outliers['Imp_Feats'] + target_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_Dataframe_Outliers_Model_2 = Main_Dataframe_Outliers.loc[:,important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 =randomforest_customized(input_dataframe=Main_Dataframe_Outliers_Model_2,\n",
    "                                               y='ln_ps4_last',\n",
    "                                       list_drop=[],\n",
    "                                     split_ratio=0.25,\n",
    "                                              fi=True,\n",
    "                                         fi_hist=True,\n",
    "                                            fi_threshold=0.01,\n",
    "                                             oob=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_Dataframe_Outliers_Model_2 = Main_Dataframe_Outliers_Model_2.drop('ln_ps4_last',axis=1)\n",
    "corr = np.round(scipy.stats.spearmanr(Main_Dataframe_Outliers_Model_2).correlation, 4)\n",
    "corr_condensed = hc.distance.squareform(1-corr)\n",
    "z = hc.linkage(corr_condensed, method='average')\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "dendrogram = hc.dendrogram(z, labels=Main_Dataframe_Outliers_Model_2.columns, orientation='left', leaf_font_size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"info\">\n",
    "\n",
    "# **THIRD MODEL**: BY REDUCING \"SIMILAR\" CLUSTERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always ensure the cluster_list contains the target label(s)\n",
    "cluster_list = ['ln_ps4_last',\n",
    "                'overall','pace_acceleration','age_imputed','phys_stamina','intl_rep','drib_composure']\n",
    "\n",
    "Main_Dataframe_Outliers_Model_3 = Main_Dataframe_Outliers.loc[:,cluster_list]\n",
    "Main_Dataframe_Outliers_Model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 =randomforest_customized(input_dataframe=Main_Dataframe_Outliers_Model_3,\n",
    "                                    y='ln_ps4_last',\n",
    "                                    list_drop=[],\n",
    "                                    split_ratio=0.25,\n",
    "                                    fi=True,\n",
    "                                    fi_hist=True,\n",
    "                                    datasets_return=True,\n",
    "                                    oob=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"success\">\n",
    "\n",
    "# **RF INTERPRETATION**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From our analysis so far, the following 5 features seem to be the most important:** \n",
    "                \n",
    "                1.Overall \n",
    "                2.Age Imputed\n",
    "                3.Pace_Acceleration\n",
    "                4.Intl_Rep\n",
    "                5.Physical_Stamina\n",
    "\n",
    "**But what are their trends and is it possible they proxying for something else?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"info\">\n",
    "\n",
    "## **UNCONDITIONAL GG-PLOTS**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GG Plots give us the reduced form relationship between our two variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing a random sample from our Main Outliers Dataset\n",
    "x_all = Main_Dataframe_Outliers.sample(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We first look at the relationship between the most important feature &mdash; a card's* **Overall** &mdash; *and* **Log Prices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(x_all, aes('overall', 'ln_ps4_last'))+stat_smooth(se=True, method='loess')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Interesting Trend:*\n",
    "**Prices are non-monotonic with Overall Quality**: Indeed we see that ln prices actually dip a little as player's quality improves from the mid-70s to the early 80s\n",
    "    \n",
    "**Possible Explanation**: *More players rising in overall from 70s to mid-80s may see a fall in other desirable attributes: Pace?*\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We next look at the relationship between the most important feature trait &mdash; a card's* **Pace_Acceleration** &mdash; *and* **Log Prices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(x_all, aes('pace_acceleration','ln_ps4_last'))+stat_smooth(se=True, method='loess')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: *We see that (for relevant rage pace_accleration > 25), Log Price monotonically increases with an increase in pace_acceleration, suggesting this is a crucial trait*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The natural question subsequently is what is the relationship between* **pace_acceleration** and **overall**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(x_all, aes('overall','pace_acceleration'))+stat_smooth(se=True, method='loess')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No evidence to claim that pace is falling with a rise in overall from mid-70s to 80s** \\\n",
    "    -Alternative Explanation: Is it possible that older players are likelier to have a higher overall, since they develop other characteristics?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(x_all, aes('age_imputed','overall'))+stat_smooth(se=True, method='loess')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** We see that* **Overall Quality** seems to rise with **(Imputed) Age** in our desired range**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(x_all, aes('age_imputed','pace_acceleration'))+stat_smooth(se=True, method='loess')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This seems to show that pace rapidly declines with age, suggesting that this might be a potential channel for explanation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"info\">\n",
    "\n",
    "## **PARTIAL DEPENDENCE PLOTS**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To add robustness to this hypothesis, let us attempt to plot some Partial Dependence Plots (PDPs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pdp(feat,chosen_model,chosen_data, clusters=None, feat_name=None):\n",
    "    feat_name = feat_name or feat\n",
    "    p = pdp.pdp_isolate(model=chosen_model['Model'],\n",
    "                        dataset=chosen_data,\n",
    "                        model_features=chosen_data.columns,\n",
    "                        feature=feat)\n",
    "    return pdp.pdp_plot(p, feat_name, plot_lines=True,\n",
    "                        cluster=clusters is not None,\n",
    "                        n_cluster_centers=clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We first sample from our training data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sample = model_3['Train_Feats'].sample(1000)\n",
    "training_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pdp('age_imputed',model_3,training_sample,clusters=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We find that age does NOT really affect prices.** *(The concentrated bump near 28-29 could be potentially due to the fact that the usually pricey Icons were randomly alloted ages using a normal distribution with mean 28.9 and an approximate sd 4)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pdp('overall',model_3,training_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We find that overall does hold a non-decreasing weakly monotonic realtionship with log prices.* **Therefore, ceteris paribus, Overall quality does not negatively really affect prices.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pdp('pace_acceleration',model_3,training_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pace (for the range of interest) seems to hold an non-decreasing and weakly monotic relationship with log prices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['overall', 'age_imputed']\n",
    "p = pdp.pdp_interact(model_3['Model'], training_sample , training_sample.columns,feats)\n",
    "pdp.pdp_interact_plot(p, feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['overall', 'pace_acceleration']\n",
    "p = pdp.pdp_interact(model_3['Model'], training_sample , training_sample.columns,feats)\n",
    "pdp.pdp_interact_plot(p, feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['age_imputed', 'pace_acceleration']\n",
    "p = pdp.pdp_interact(model_3['Model'], training_sample , training_sample.columns,feats)\n",
    "pdp.pdp_interact_plot(p, feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Focusing on the region with pace_acceleration above 40 (few players among the elite have pace below 40), and ignoring the narrow age range in the middle (due to the imputation reasons discussed earlier), we note the following the points:** \n",
    "1. **Age** and **Pace_acceleration** do not seem to interact in many ways substantially most of the time, as pace is more important factor\n",
    "2. However, the interaction does seem to be substantial in the case where a player is both old AND slow, in which case the prices actually are the lowest\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_Dataframe_Outliers['pace_acceleration'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"success\">\n",
    "\n",
    "# **Conclusion**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our Final Model is thus:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 =randomforest_customized(input_dataframe=Main_Dataframe_Outliers_Model_3,\n",
    "                                    y='ln_ps4_last',\n",
    "                                    list_drop=[],\n",
    "                                    split_ratio=0.25,\n",
    "                                    fi=True,\n",
    "                                    fi_hist=True,\n",
    "                                    datasets_return=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
